{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will be used to load MATLAB mat datafile format\n",
    "from scipy.io import loadmat\n",
    "from scipy import optimize\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeRatings(Y, R):\n",
    "    \"\"\"\n",
    "    Preprocess data by subtracting mean rating for every movie (every row)\n",
    "    \"\"\"\n",
    "    m, n = Y.shape\n",
    "    Ymean = np.zeros(m)\n",
    "    Ynorm = np.zeros(Y.shape)\n",
    "\n",
    "    for i in range(m):\n",
    "        idx = R[i, :] == 1\n",
    "        Ymean[i] = np.mean(Y[i, idx])\n",
    "        Ynorm[i, idx] = Y[i, idx] - Ymean[i]\n",
    "\n",
    "    return Ynorm, Ymean\n",
    "\n",
    "def loadMovieList():\n",
    "    \"\"\"\n",
    "    Reads the fixed movie list in movie_ids.txt and returns a list of movie names.\n",
    "    Returns\n",
    "    -------\n",
    "    movieNames : list\n",
    "        A list of strings, representing all movie names.\n",
    "    \"\"\"\n",
    "    # Read the fixed movieulary list\n",
    "    with open(\"movie_ids.txt\", encoding=\"ISO-8859-1\") as fid:\n",
    "        movies = fid.readlines()\n",
    "\n",
    "    movieNames = []\n",
    "    for movie in movies:\n",
    "        parts = movie.split()\n",
    "        movieNames.append(\" \".join(parts[1:]).strip())\n",
    "        return movieNames\n",
    "    \n",
    "def computeNumericalGradient(J, theta, e=1e-4):\n",
    "    \"\"\"\n",
    "    Computes the gradient using \"finite differences\" and gives us a numerical estimate of the gradient\n",
    "    \"\"\"\n",
    "    numgrad = np.zeros(theta.shape)\n",
    "    perturb = np.diag(e * np.ones(theta.shape))\n",
    "\n",
    "    for i in range(theta.size):\n",
    "        loss1, _ = J(theta - perturb[:, i])\n",
    "        loss2, _ = J(theta + perturb[:, i])\n",
    "        numgrad[i] = (loss2 - loss1)/(2*e)\n",
    "    return numgrad\n",
    "\n",
    "\n",
    "def checkCostFunction(cofiCostFunc, lambda_=0.):\n",
    "    \"\"\"\n",
    "    Creates a collaborative filtering problem to check your cost function and gradients.\n",
    "    It will output the analytical gradients produced by your code and the numerical gradients\n",
    "    (computed using computeNumericalGradient). These two gradient computations should result in very similar values \n",
    "    \"\"\"\n",
    "    # Create small problem\n",
    "    X_t = np.random.rand(4, 3)\n",
    "    Theta_t = np.random.rand(5, 3)\n",
    "\n",
    "    # Zap out most entries\n",
    "    Y = np.dot(X_t, Theta_t.T)\n",
    "    Y[np.random.rand(*Y.shape) > 0.5] = 0\n",
    "    R = np.zeros(Y.shape)\n",
    "    R[Y != 0] = 1\n",
    "\n",
    "    # Run Gradient Checking\n",
    "    X = np.random.randn(*X_t.shape)\n",
    "    Theta = np.random.randn(*Theta_t.shape)\n",
    "    num_movies, num_users = Y.shape\n",
    "    num_features = Theta_t.shape[1]\n",
    "    params = np.concatenate([X.ravel(), Theta.ravel()])\n",
    "    numgrad = computeNumericalGradient(\n",
    "        lambda x: cofiCostFunc(x, Y, R, num_users, num_movies, num_features, lambda_), params)\n",
    "    \n",
    "    cost, grad = cofiCostFunc(params, Y, R, num_users, num_movies, num_features, lambda_)\n",
    "\n",
    "    print(np.stack([numgrad, grad], axis=1))\n",
    "    print(\"\\nThe above two columns you get should be very similar.\"\n",
    "          \"(Left-Your Numerical Gradient, Right-Analytical Gradient)\")\n",
    "    \n",
    "    diff = np.linalg.norm(numgrad-grad)/np.linalg.norm(numgrad+grad)\n",
    "    print(\"If your cost function implementation is correct, then \"\n",
    "          \"the relative difference will be small (less than 1e-9).\")\n",
    "    print(\"\\nRelative Difference: %g\" % diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recomennder systems\n",
    "\n",
    "In this part of the exercise you will implement the collaborative filtering learning algorithm and apply it to a dataset of movie ratings (MovieLens 100k Dataset from GroupLens Research). This dataset consists of rating on a scale of 1 to 5. The dataset has ***943 users*** and ***1682 movies***.\n",
    "\n",
    "In the next parts of this exercise you will implement the function ***cofiCostFunc*** that computes the collaborative filtering objective function and gradient. After implementing the cost function and gradient you will use scipy.optimize.minimize to learn the parameters for collaborative filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Movie ratings dataset\n",
    "\n",
    "The next cell will load the dataset ***ex8_movies.mat*** providing the variables ***Y*** and ***R***. The matrix ***Y***(a ***num_movies*** x ***num_users*** matrix) stores the rating ***y*** (from 1 to 5). The matrix ***R*** is a binary-valued indicator matrix, where ***R(i,j)=1*** if user j gave a rating to movie i, and ***R(i,j)=0*** otherwise. The objective of collaborative filtering is to predict movie ratings for the movie that users have not yet rated, that is the entries with ***R(i,j)=0***. This will allow us to recommend the movies with the highest predicted ratings to the user.\n",
    "\n",
    "To help you understand the matrix ***Y***, the following cell will compute the avarage movie rating for the first movie (Toy Story) and print its avarage rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = loadMovieList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = loadmat('movies.mat')\n",
    "Y, R = data['Y'], data['R']\n",
    "\n",
    "# Y is a 1682x943 matrix, containing ratings (1-5) of \n",
    "# 1682 movies on 943 users\n",
    "\n",
    "# R is a 1682x943 matrix, where R(i,j) = 1 \n",
    "# if and only if user j gave a rating to movie i\n",
    "\n",
    "# From the matrix, we can compute statistics like average rating.\n",
    "print('Average rating for movie 1601 (',names[1600] ,'): %f / 5' %\n",
    "      np.mean(Y[1600, R[0, :]]))\n",
    "\n",
    "# We can \"visualize\" the ratings matrix by plotting it with imshow\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(Y)\n",
    "plt.ylabel('Movies')\n",
    "plt.xlabel('Users')\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this part of the exercise, you will also be working with the matrices, `X` and `W`:\n",
    "\n",
    "$$ \\text{X} = \n",
    "\\begin{bmatrix}\n",
    "- \\left(x^{(1)}\\right)^T - \\\\\n",
    "- \\left(x^{(2)}\\right)^T - \\\\\n",
    "\\vdots \\\\\n",
    "- \\left(x^{(n_m)}\\right)^T - \\\\\n",
    "\\end{bmatrix}, \\quad\n",
    "\\text{W} = \n",
    "\\begin{bmatrix}\n",
    "- \\left(w^{(1)}\\right)^T - \\\\\n",
    "- \\left(w^{(2)}\\right)^T - \\\\\n",
    "\\vdots \\\\\n",
    "- \\left(w^{(n_u)}\\right)^T - \\\\\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "The $i^{th}$ row of `X` corresponds to the feature vector $x^{(i)}$ for the $i^{th}$ movie, and the $j^{th}$ row of `W` corresponds to one parameter vector $w^{(j)}$, for the $j^{th}$ user. Both $x^{(i)}$ and $w^{(j)}$ are n-dimensional vectors. For the purposes of this exercise, you will use $n = 100$, and therefore, $x^{(i)} \\in \\mathbb{R}^{100}$ and $w^{(j)} \\in \\mathbb{R}^{100}$. Correspondingly, `X` is a $n_m \\times 100$ matrix and `W` is a $n_u \\times 100$ matrix.\n",
    "\n",
    "<a id=\"section3\"></a>\n",
    "### 2.2 Collaborative filtering learning algorithm\n",
    "\n",
    "Now, you will start implementing the collaborative filtering learning algorithm. You will start by implementing the cost function (without regularization).\n",
    "\n",
    "The collaborative filtering algorithm in the setting of movie recommendations considers a set of n-dimensional parameter vectors $x^{(1)}, \\dots, x^{(n_m)}$ and $w^{(1)} , \\dots, w^{(n_u)}$, where the model predicts the rating for movie $i$ by user $j$ as $y^{(i,j)} = \\left( w^{(j)} \\right)^T x^{(i)}$. Given a dataset that consists of a set of ratings produced by some users on some movies, you wish to learn the parameter vectors $x^{(1)}, \\dots, x^{(n_m)}, w^{(1)}, \\dots, w^{(n_u)}$ that produce the best fit (minimizes the squared error).\n",
    "\n",
    "You will complete the code in `cofiCostFunc` to compute the cost function and gradient for collaborative filtering. Note that the parameters to the function (i.e., the values that you are trying to learn) are `X` and `W`. In order to use an off-the-shelf minimizer such as `scipy`'s `minimize` function, the cost function has been set up to unroll the parameters into a single vector called `params`. You had previously used the same vector unrolling method in the neural networks programming exercise.\n",
    "\n",
    "#### 2.2.1 Collaborative filtering cost function\n",
    "\n",
    "The collaborative filtering cost function (without regularization) is given by\n",
    "\n",
    "$$\n",
    "J(x^{(1)}, \\dots, x^{(n_m)}, w^{(1)}, \\dots, w^{(n_u)}) = \\frac{1}{2} \\sum_{(i,j):r(i,j)=1} \\left( \\left(w^{(j)}\\right)^T x^{(i)} - y^{(i,j)} \\right)^2\n",
    "$$\n",
    "\n",
    "You should now modify the function `cofiCostFunc` to return this cost in the variable `J`. Note that you should be accumulating the cost for user $j$ and movie $i$ only if `R[i,j] = 1`.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "**Implementation Note**: We strongly encourage you to use a vectorized implementation to compute $J$, since it will later by called many times by `scipy`'s optimization package. As usual, it might be easiest to first write a non-vectorized implementation (to make sure you have the right answer), and the modify it to become a vectorized implementation (checking that the vectorization steps do not change your algorithmâ€™s output). To come up with a vectorized implementation, the following tip might be helpful: You can use the $R$ matrix to set selected entries to 0. For example, `R * M` will do an element-wise multiplication between `M`\n",
    "and `R`; since `R` only has elements with values either 0 or 1, this has the effect of setting the elements of M to 0 only when the corresponding value in R is 0. Hence, `np.sum( R * M)` is the sum of all the elements of `M` for which the corresponding element in `R` equals 1.\n",
    "</div>\n",
    "\n",
    "<a id=\"cofiCostFunc\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cofiCostFunc(params, Y, R, num_users, num_movies, num_features, lambda_=0.0):\n",
    "    # Unfold the U and W matrices from params\n",
    "    X = params[:num_movies*num_features].reshape(num_movies, num_features)\n",
    "    Theta = params[num_movies*num_features:].reshape(num_users, num_features)\n",
    "\n",
    "    # You need to return the following values correctly\n",
    "    J = 0\n",
    "    X_grad = np.zeros(X.shape)\n",
    "    Theta_grad = np.zeros(Theta.shape)\n",
    "\n",
    "    # ============= YOUR CODE HERE =============\n",
    "\n",
    "    J = (1 / 2) * np.sum(np.square((X.dot(Theta.T) - Y) * R)) + (lambda_ / 2) * np.sum(np.square(X)) + (lambda_ / 2) * np.sum(np.square(Theta))\n",
    "\n",
    "    for i in range(R.shape[0]):\n",
    "\n",
    "        idx = np.where(R[i, :] == 1)[0]\n",
    "        Theta_temp = Theta[idx, :]\n",
    "        Y_temp = Y[i, idx]\n",
    "        X_grad[i, :] = np.dot(np.dot(X[i, :], Theta_temp.T) - Y_temp, Theta_temp) + lambda_ * X[i, :]\n",
    "\n",
    "    for j in range(R.shape[1]):\n",
    "\n",
    "        idx = np.where(R[:, j] == 1)[0]\n",
    "        X_temp = X[idx, :]\n",
    "        Y_temp = Y[idx, j]\n",
    "        Theta_grad[j, :] = np.dot(np.dot(X_temp, Theta[j, :]) - Y_temp, X_temp) + lambda_ * Theta[j, :]\n",
    "\n",
    "    # ==============================================\n",
    "\n",
    "    grad = np.concatenate([X_grad.ravel(), Theta_grad.ravel()])\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have completed the function, the next cell will run cost function. To help you debug your cost function, we have included set of weights that we trained on that. You should expect to see an output of 22.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained weights (X, Theta, num_users, num_movies, num_features)\n",
    "data = loadmat(os.path.join(path, \"movieParams.mat\"))\n",
    "X, Theta, num_users, num_movies, num_features = data[\"X\"], data[\"Theta\"], data[\"num_users\"], data[\"num_movies\"], data[\"num_features\"]\n",
    "\n",
    "# Reduce the data set size so that this runs faster\n",
    "num_users = 4\n",
    "num_movies = 5\n",
    "num_features = 3\n",
    "\n",
    "X = X[:num_movies, :num_features]\n",
    "Theta = Theta[:num_users, :num_features]\n",
    "Y = Y[:num_movies, 0:num_users]\n",
    "R = R[:num_movies, 0:num_users]\n",
    "\n",
    "# Evaluate cost function\n",
    "J, _ = cofiCostFunc(np.concatenate([X.ravel(), Theta.ravel()]), Y, R, num_users, num_movies, num_features)\n",
    "\n",
    "print(\"Cost at loaded parameters: %.2f \\n(this value should be about 22.22)\" % J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check gradients by running checkCostFunction\n",
    "checkCostFunction(cofiCostFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate cost function\n",
    "J, _ = cofiCostFunc(np.concatenate([X.ravel(), Theta.ravel()]), Y, R, num_users, num_movies, num_features, 1.5)\n",
    "print(\"Cost at loaded parameters (lambda = 1.5): %.2f\" % J)\n",
    "print(\"               (this value should be about 31.34)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Learning movie recommendations \n",
    "\n",
    "After you have finished implementing the collaborative filtering cost function and gradient, you can now start training your algorithm to make movie recommendations for yourself. In the next cell, you can enter your own movie preferences, so that later when the algorithm runs, you can get your own movie recommendations! We have filled out some values according to our own preferences, but you should change this according to your own tastes. The list of all movies and their number in the dataset can be found listed in the file `Data/movie_idx.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we will train collaborative filtering model, we will first\n",
    "# add ratings that correspond to a new user that we just observed.\n",
    "# This part of the code will also allow you to put in your own ratings\n",
    "# for the movies in our dataset!\n",
    "\n",
    "movieList = loadMovieList()\n",
    "n_m = len(movieList)\n",
    "\n",
    "# Initialize my ratings\n",
    "my_ratings = np.zeros(n_m)\n",
    "\n",
    "# Check the file movi_idx.txt for id of each movie in our dataset\n",
    "# For example, Toy Story (1995) has ID 1, so to rate it \"4\", you can set\n",
    "# note that the index here is ID-1, since we start index from 0\n",
    "my_ratings[0] = 4\n",
    "\n",
    "# Or suppose did not enjoy Silence of the Lambs (1991), you can set\n",
    "my_ratings[97] = 2\n",
    "\n",
    "# We have selected a few movies we liked / did not like and the ratings we \n",
    "# gave are as follows:\n",
    "my_ratings[6] = 3\n",
    "my_ratings[11] = 5\n",
    "my_ratings[53] = 4\n",
    "my_ratings[63] = 5\n",
    "my_ratings[65] = 3\n",
    "my_ratings[68] = 5\n",
    "my_ratings[182] = 4\n",
    "my_ratings[225] = 5\n",
    "my_ratings[354] = 5\n",
    "\n",
    "print(\"New user ratings:\")\n",
    "print(\"-----------------\")\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0:\n",
    "        print(\"Rated %d stars: %s\" % (my_ratings[i], movieList[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_id_list = [0, 97, 6, 11, 53, 63, 65, 68, 182, 225, 354]\n",
    "\n",
    "for movie in movies_id_list:\n",
    "  print(movieList[movie])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Recommendations\n",
    "\n",
    "After the additional ratings have been added to the dataset, the script\n",
    "will proceed to train the collaborative filtering model. This will learn the\n",
    "parameters `X` and `W`. To predict the rating of movie $i$ for user $j$, you need to compute $(w^{(j)})^T x^{(i)}$ . The next part of the script computes the ratings for\n",
    "all the movies and users and displays the movies that it recommends (Figure\n",
    "4), according to ratings that were entered earlier in the script. Note that\n",
    "you might obtain a different set of the predictions due to different random\n",
    "initializations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you will train the collaborative filtering model on a movie rating \n",
    "# dataset of 1682 movies and 943 users\n",
    "\n",
    "# Load data\n",
    "data = loadmat(os.path.join(path, \"movies.mat\"))\n",
    "Y, R = data[\"Y\"], data[\"R\"]\n",
    "\n",
    "# Y is a 1682x943 matrix, containing ratings (1-5) of 1682 movies by 943 users\n",
    "# R is a 1682X943 matrix, where R(i, j) = 1 if and only if user j rated movie i\n",
    "\n",
    "# Add our own ratings to the data matrix\n",
    "Y = np.hstack([my_ratings[:, None], Y])\n",
    "R = np.hstack([(my_ratings > 0)[:, None], R])\n",
    "\n",
    "# Normalize Ratings\n",
    "Ynorm, Ymean = normalizeRatings(Y, R)\n",
    "\n",
    "# Useful values\n",
    "num_movies, num_users = Y.shape\n",
    "num_features = 10\n",
    "\n",
    "# Set Initial Parameters (Theta, X)\n",
    "X = np.random.randn(num_movies, num_features)\n",
    "Theta = np.random.randn(num_users, num_features)\n",
    "\n",
    "initial_parameters = np.concatenate([X.ravel(), Theta.ravel()])\n",
    "\n",
    "#Set options for scipy.optimize.minimize\n",
    "options = {\"maxiter\": 100}\n",
    "\n",
    "# Set Regularization\n",
    "lambda_ = 10\n",
    "res = optimize.minimize(lambda x: cofiCostFunc(x, Ynorm, R, num_users, num_movies, num_features, lambda_),\n",
    "                        initial_parameters,\n",
    "                        method=\"TNC\",\n",
    "                        jac=True,\n",
    "                        options=options)\n",
    "theta = res.x\n",
    "\n",
    "# Unfold the returned theta back into U and W\n",
    "X = theta[:num_movies*num_features].reshape(num_movies, num_features)\n",
    "Theta = theta[num_movies*num_features:].reshape(num_users, num_features)\n",
    "\n",
    "print(\"Recommender system learning completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the model, you can now make recommendations by computing the predictions matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.dot(X, Theta.T)\n",
    "my_predictions = p[:, 0] + Ymean\n",
    "\n",
    "movieList = loadMovieList()\n",
    "\n",
    "ix = np.argsort(my_predictions)[::-1]\n",
    "\n",
    "print(\"Top recommendations for you:\")\n",
    "print(\"----------------------------\")\n",
    "for i in range(10):\n",
    "    j = ix[i]\n",
    "    print(\"Predicting rating %.1f for movie %s\" % (my_predictions[j], movieList[j]))\n",
    "\n",
    "print(\"\\nOriginal ratings provided:\")\n",
    "print(\"----------------------------\")\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0:\n",
    "        print(\"Rated %d for %s\" % (my_ratings[i], movieList[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
